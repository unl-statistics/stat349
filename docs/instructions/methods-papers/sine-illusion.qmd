---
title: "Signs of the Sine Illusion: Why We Need to Care"
author: "Susan Vanderplas & Heike Hofmann"
abstract: | 
  Graphical representations have to be true to the data they display. Computational tools ensure this on a technical level. But we also need to take 'flaws' of the human perceptual system into account. The sine illusion provides an example where human perception leads to systematic bias in the assessment of the optical stimulus, with a particularly notable impact on perception of time-series data with a seasonal component. In this paper, we discuss the reasons for the illusion and various strategies  useful to break the illusion or reduce its strength. We demonstrate the presence of the illusion in real-world and theoretical situations. We also present data from a user study which demonstrate the dramatic effect the sine illusion can have on conclusions drawn from displayed data.
bibliography: references.bib
number-sections: true
number-depth: 3
---

::: hidden
$$      
\newcommand{\range}[1]{{\text{range}\left(#1\right)}}
      \newcommand{\s}[2]{{_{#1}s^{ #2}}}
      \newcommand{\atan}[1]{\text{atan}\left({#1}\right)}
      \newcommand{\xR}{\mathbb{R}}
$$
:::

```{=html}
<style>
.design {background-color: #99ff2222}
.setting {background-color: #ff000022}
.sampling {background-color: #0000ff22}
.variables {background-color: #ff00ff22}
.statistics {background-color: #ffff0022}
</style>
```



# Introduction

Graphics are powerful tools for summarizing large or complex data, but they rely on the main premise that any graphical representation of the data has to be "true" to the data [see e.g. @tufte; @wainer:2000; @robbins:2005].
That is, a measurable quantity of a graphical element in the representation has to directly reflect some aspect of the underlying data.
Generally, we see a lot of discussion on keeping true to the data in the framework of (ab)using three dimensional effects in graphics.
@tufte goes as far as defining a *lie-factor* of a chart as the ratio of the size of an effect in the data compared to the size of an effect shown, with the premise that any large deviations from a value of one indicate a misuse of graphical techniques.
Computational tools help us ensure technical accuracy -- but this brings up the additional question of how we deal with situations that involve innate inability or trigger learned misperceptions in the audience.
In this paper we want to raise awareness for one of these situations, known as the *sine illusion* or *line width illusion* .
Based on the results of a human subject study in @sec-study we can show that this phenomenon manifests itself frequently and persistently in our dealings with statistical graphics.
In @sec-solutions we provide a set of strategies to mitigate the effects of the illusion.
Again, results from the subject study are given to show that there is a wide range of possible values in the parameter space of the solution that provide relief from the distortive effects of the illusion in the general population.

::: {#fig-examplefull layout-ncol="2"}
![Scatterplot of Ozone and Temperature in Houston, 2011. A loess fit shows the overall trend.](figure/fig-example-1.png){#fig-examplefull-1 fig-alt="The figure is a scatterplot showing Temperature in fahrenheit on the x-axis (45-95 degrees) and 8-hour average ozone concentration in ppm on the y-axis (ranging from around 0 to around .09). There is an increasing trend, shown by a loess smooth line, but it is not linear - there is a bump around 70 degrees where the increase is much more steep."}

![Scatterplots of Ozone and Temperature de-trended according to the loess fit in (a).](figure/fig-example-2.png){#fig-examplefull-2 fig-alt="The figure is a scatterplot showing Temperature in fahrenheit on the x-axis (45-95 degrees) and residual 8-hour average ozone concentration in ppm on the y-axis (ranging from -0.04 to around .04). There is a clear increase in residual variance over the course of the span of the x-axis."}

Scatterplots of Ozone and Temperature in Houston, 2011.
The increase in variability over the temperature range is more pronounced in the de-trended plot on the right.
:::

As a first example let us consider the relationship between ozone concentration and temperature.
Ozone concentrations were measured from 21 locations in the Houston area [@epa], and temperature data are provided by the NCDC [@noaa] site at Hobby International Airport, located near the center of Houston.

@fig-examplefull-1 shows daily measurements of 8-hour average ozone concentration and temperature at several sites in Houston, for days in 2011 with temperatures above $45^\circ$F and dew points of less than $60^\circ$F.
A loess smooth line is added for reference.
These types of plots are often used to give an overview of the relationship between two variables.
The trend line summarizes this relationship, while the points show raw measurement to allow an assessment of the overall size of the data, the amount of (marginal) variability presented, as well as the (conditional) variability along the trend line.
It is the latter task that we cannot satisfactorily complete.
While we might agree that there is an increase in variability of ozone concentrations for temperatures above $80^\circ$F, we will not doubt homogeneity elsewhere based on @fig-examplefull-1.

This evaluation changes when considering @fig-examplefull-2: the scatterplot shows a loess based de-trended residual of temperature.
The previously almost invisible increase in variability of ozone measurements with increasing temperatures now becomes apparent.

This phenomenon, caused by the change in the slope of the trend line, is known as the *sine illusion* in the literature on cognition and human perception or *line width illusion* in the statistical graphics literature.

In the cognitive literature, @day:1991 first documented the illusion in the context of vertical lines along a sinusoidal curve.
@fig-original shows a sketch of this: line segments are centered evenly spaced along the curve.
Line segments are of equal length but appear longer in the peaks and troughs due to the illusion.
The parameters that influence the strength of the illusion are the amplitude of the curve and the length of the line segments.
As the length of the line segments increases, the apparent difference in the length of the line segments decreases.
Any modification that increases the change in slope under which the curve appears, such as an increase in the amplitude of the curve or a more extreme aspect ratio, reinforces the apparent difference in line lengths.

![The original sine illusion was demonstrated on evenly spaced vertical lines centered around a sinusoidal curve of $f(x) = \sin(x)$. The lines in the peak and trough of the curve appear to be longer than in the other regions.](figure/fig-original-1.png){#fig-original fig-alt="A set of vertical lines where each line is centered along an invisible sine curve."}

More recently the illusion has been shown in non-sinusoidal curves [@cleveland:1984; @schonlau:2003; @robbins:2005; @marie:2013], but the underlying effect seems to be the same, in the sense that the illusion is not triggered by the periodic nature of the underlying trend line but only by changes to its slope.

Next, we examine the perceptual and statistical literature regarding this illusion.

### The Sine Illusion in Statistical Graphics {#statisticalgraphics}

The Sine Illusion in Statistical Graphics has been frequently noted , though usually not as an optical illusion.
Rather, the problem is typically identified as the difficulty of visually subtracting two curves [see e.g. @robbins:2005 p. 35 or @cleveland:1984 p. 549] and the resulting erroneous conclusions when this process goes awry.
Playfair's chart of the balance of trade between England and the East Indies [@playfair; @playfair2] (shown in @sec-app-graphics) represents the possibly oldest example of this common phenomenon.

In more modern visualizations, bivariate area charts and "stream graphs" [@stackedgraphs] commonly produce the illusion (see an example at <http://bl.ocks.org/mbostock/3894205>).

### Perceptual Explanations for the Sine Illusion {#sec-perceptualexplanations}

Perceptual explanations for the sine illusion can be found in the sensation and perception literature.
While not thoroughly examined, the sine illusion has been classified as part of a group of geometrical optical mis-perceptions related to the M"uller-Lyer illusion [@day:1991] or the Poggendorf illusion [@poggendorf], which puts the illusion into the framework of context-based illusions. @day:1991 suggest that the sine illusion occurs due to misapplication of perceptual experience with the three-dimensional world to a two-dimensional "artificial" display of data.

Experience with real-world objects suggests that the stimulus of @fig-original is very similar to a slightly angled top view of the 3-dimensional figure of a strip or ribbon describing waves in a third dimension, such as e.g.\~a road does on rolling hills.
This is sketched out in @fig-ribbon1.
Our real-world experience suggests immediately that changes in the width of the road are unlikely and resolves the representation accordingly.
@fig-ribbon1 shows the line segments slightly angled towards each other.
In contrast to that, @fig-ribbon2 shows a variation of the same plot with a vanishing point set further away from the viewer.
This makes the line segments almost parallel to each other and the representation therefore more closely resembles the sketch of @fig-original, in which the sine illusion was originally presented.

::: {#fig-ribbon layout-ncol="2"}
![Perspective plot of sine illusion](figure/fig-ribbon-illusion-1.png){#fig-ribbon1 fig-alt="A Perspective plot of the sine illusion"}

![Perspective plot, vanishing point near infinity.](figure/fig-ribbon-illusion-2.png){#fig-ribbon2 fig-alt="Perspective plot, vanishing point near infinity."}

Two different perspective projections of the same data responsible for the sine illusion.
The first projection angles the lines and appears more natural, but the second projection suggests that the lines do not need to be angled to create the same 3d impression.
:::

![The sine illusion with two individual lines highlighted. Horizontal grid lines do not help to resolve the illusion, even though they provide a clear basis for comparison of line lengths. Readers are much better at assessing the length of the two singled out line segments; they are equal.](figure/fig-originalgrid-1.png){#fig-original-grid fig-alt="The sine illusion with two individual lines highlighted. Horizontal grid lines do not help  to resolve the illusion, even though they provide a clear basis for comparison of line lengths. Readers are much better at assessing the length of the two singled out line segments; they are equal."}

Recreating the three-dimensional context of the sine illusion might resolve the distortion.
Generally, an increase of the dimensionality of a graph is not recommended [@tufte; @cleveland:1984], but @spence:1990 suggests that adding a third dimension to simple statistical graphics does not interfere with an accurate reading.

However, for the sine illusion, the process of projecting the data accurately into a higher dimension is not simple.
The projection that best resolves the illusion likely is highly subjective and influenced by choices of angle and color gradient for depth cues.
As there is not a single three-dimensional projection that corresponds to the two-dimensional data, this approach would only produce further visual ambiguity.

To further complicate the situation, the illusion itself is insidious -- we trust our vision implicitly, to the point that when we understand something, we say "I see".
This trust in our visual perception is seldom called into question, for our perception is optimized for interaction with a three-dimensional world.
Artificial two-dimensional situations (such as graphs and pictures) may accurately represent the data and still produce a misleading perceptual experience.

The contextual cues of the overall trend are critical to the sine illusion's effect; the illusion only holds when a substantial portion of the graph is considered simultaneously, which triggers our innate ability of perceiving one whole rather than the individual parts it consists of @wolfe2012sensation (principle of grouping).

Considering only two line segments at a time resolves the illusion.
The bold lines in @fig-original-grid are clearly of the same length.
Comparisons of individual line lengths is visually a fairly simple task, and is done with a relatively high accuracy [@cleveland:1984].
@day:1991 contains a more thorough discussion of how much context is required for the illusion to persist.

### The Geometry of the Illusion

The geometry of the illusion is driven by our preference in evaluating line width as *orthogonal* width rather than the difference along the vertical axis.
@fig-OrthogonalWidth demonstrates the change in orthogonal width as the slope of the line tangent to the graph of $f$ changes; these changes correspond to our perception of apparent line length.

![The sine illusion with lines orthogonal to the tangent line at $f(x)$. The perception that the vertical length changes with $f(x)$ corresponds to changes in actual orthogonal width due to the change in the visual (plotted) secant angle. The strength of the perceptual effect depends in part on the aspect ratio of the graph, as shown in the second image.](figure/fig-transform-illustration-1.png){#fig-OrthogonalWidth fig-alt="The sine illusion with lines orthogonal to the tangent line at $f(x)$. The perception that the vertical length changes with $f(x)$ corresponds to changes in actual orthogonal width due to the change in the visual (plotted) secant angle. The strength of the perceptual effect depends in part on the aspect ratio of the graph, as shown in the second image."}

The illusion is most pronounced in regions where the angle between the orthogonal and the vertical line is large.
Changes to the aspect ratio therefore have a major impact on the strength of the sine illusion.
Any measure that alleviates the difference between perceived width and the perpendicular width, decreases the effect of the illusion but does not completely overcome it.
Banking to 45$^\circ$ [@cleveland:88] has been suggested as a good default aspect ratio for time series, but does not necessarily help in the situation of the sine illusion, as the example in @sec-example shows, as the illusion would only be worsened by banking to 45$^\circ$.
The perceived length of the vertical line changes with the angle of the line perpendicular to the slope of $\sin(x)$, suggesting that the sine illusion stems from a conflict between the visual system's perception of figure width and the mathematical judgment necessary to determine the length of the vertical lines.

Our preference for assessing figure width based on the orthogonal width suggests that the underlying illusion may be a function of geometry rather than some unknown visual or neural process that occurs subconsciously.
In this case it may be possible to correct the graphical display for the illusion to minimize its misleading effect.
A geometrical correction that -- at least temporarily -- counteracts the illusion would be a valuable tool in visual analysis, as this illusion very persistently affects our judgment of very common tasks such as e.g. the assessment of conditional variability of data along a trend line.

What follows is a compilation of several approaches to correct for or mitigate the effect of the illusion.
Our primary intent here is to demonstrate the pervasiveness of the illusion and the extreme measures necessary to remove its effect.

# Breaking the Illusion {#sec-solutions}

The sine illusion is caused by a conflict between vertical width, which is the width that we want onlookers to assess visually, and orthogonal width, which is the width that the onlooker perceives.
This difference can be expressed as a function in the slope of the underlying trend line.
This forms the basis for adjusting the vertical width for the perceived orthogonal width in the following three approaches:

1.  separation of trend and variability,
2.  transformation of $x$: adjusting slope to be constant by reparameterizing the $x$ axis, and
3.  transformation of $y$: adjusting $y$ values to make conditional variability appear correctly

Each of these ideas is discussed in more detail in this section.

## Trend Removal

@cleveland:1984, @cleveland:1985 discuss the perceptual difficulty of judging the difference between two curves plotted in the same chart, and alternatively, recommend to display the difference between the two curves directly.
This is in line with recommendations for good graphics to 'show the data' rather than make the reader derive some aspect of it [e.g. @wainer:2000].

While the illusion is not apparent when trend line and variability in the residual structure are shown separately, the separation makes it more difficult to evaluate the overall pattern in the data, as we must base any judgment on two charts; either by combining information from two graphs or by mentally re-composing the original graph (at which point, the sine illusion becomes a factor).
To minimize cognitive demands stemming from our limited visual memory [@healey:2012] we ideally want to tell the whole story with a single graph, in particular because in many situations we may not be able to show multiple graphs due to space limitations (such as in journal publications) or time and attention limitations (in presentations).

Additionally, removing the trend requires an initial model, making any plots produced using that fit conditional on the assumptions necessary to obtain that model fit.
%In many situations, this may be undesirable.
In particular, As we typically view the data before fitting even a rudimentary model, these initial modeling decisions might already be influenced by the sine illusion.

## Transformation of the $X$-Axis

The sine illusion is driven by changes in the slope of trends between variables, we can therefore counteract the illusion by removing these changes, transforming the $x$ axis such that the absolute value of the slope is constant and forcing the corresponding orthogonal width to represent the conditional variability.

Let us assume that the relationship between variables $X$ and $Y$ is given by a model of the form \$ y = f(x) + \varepsilon\$, where $f$ is some underlying function (either previously known or based on a model fit), that is differentiable over the region of observed data.

For a correction, we want to find a transformation $T(x)$ of $x$, such that $f(T(x))$ is a piece-wise linear function, where each piece has the same absolute slope.
%This transformation has an effect similar to "banking to 45$^\circ$" in a piecewise manner.

Let $a$ and $b$ be the minimum and maximum of the $x$-range under consideration.
Then for any value $x \in (a,b)$ the following transformation results in a function with constant absolute slope (see @sec-app-xtrans for a derivation of the equation):

$$
(f \circ T)(x) = a + (b-a)\left(\int_{a}^x |f^\prime(z)| dz\right)/\left(\int_{a}^{b}|f^\prime(z)| dz\right),
$$ {#eq-xtrans}

The transformed $x$-axis is changed from a linear representation of the $x$ values to a 'warped' axis that continuously changes the scale of $x$ to compensate for changes in the slope.
To emphasize this change in scale along the $x$ axis, dots are drawn at the bottom of the chart to show the transformation's effect on equally spaced points along the $x$-axis.
Results from this transformation are demonstrated in @fig-xtrans1.

::: {#fig-xtrans layout-ncol="2"}
![$X$ axis transformation based on @eq-xtrans, corresponding to weighting of $w=1$.](figure/fig-xtransform-1.png){#fig-xtrans1 fig-alt="X axis transformation of the sine illusion corresponding to $w=1$."}

![Weighted Transformation, $w=1/2$ (based on @eq-xtrans-weighted)](figure/fig-xtransform-2.png){#fig-xtrans2 fig-alt="X axis transformation of the sine illusion corresponding to $w=1/2$."}

![Weighted Transformation, $w=1/3$ (based on @eq-xtrans-weighted)](figure/fig-xtransform-3.png){#fig-xtrans3 fig-alt="X axis transformation of the sine illusion corresponding to $w=1/3$."}

![Weighted Transformation, $w=1/4$ (based on @eq-xtrans-weighted)](figure/fig-xtransform-4.png){#fig-xtrans4 fig-alt="X axis transformation of the sine illusion corresponding to $w=1/4$."}

Examples of $X$ axis transformations in the sine curve.
Dots at the bottom of the graph show the transformation's effect on equally spaced points along the $x$-axis.
Different amounts of weighting $w$ correspond to differently strong corrections.
In (a), $x$-spacing of the lines changes the extant width such that the absolute value of the slope is uniform across the whole range of the $x$ axis resulting in the largest amount of correction.
(b) - (d) reduce the correction in (a) towards successively more uniform spacing in $x$ while still breaking the effects of the illusion.
:::

While the transformation in @eq-xtrans effectively removes the appearance of changing line lengths, we can see in practice that the illusion can be broken by a much less severe transformation of the $x$ axis.
For that we introduce a shrinkage factor $w \in (0,1)$ that allows a weighted approach in counteracting the illusion as:

$$
(f \circ T_w)(x) = (1-w) \cdot x + w \cdot (f \circ T)(x)
$$ {#eq-xtrans-weighted}

Note that for $w=1$ the $x$-transformation is applied completely, while smaller values of $w$ indicate a less severe adjustment, %.
Under weaker transformations, which lets the data more closely reflect the original function $f(x)$.
@fig-xtrans2 - @fig-xtrans4 show the effect of different shrinkage values $w$.
As $w$ decreases, the lines become more evenly spaced and the illusion begins to return.
The extent to which we can shrink the adjustment back to the original function varies with the aspect ratio of the chart and the function shape.

## Transformation in $Y$

Understanding the geometry of the sine illusion leads to another approach of resolving the conflict between the orthogonal width and the vertical length of the segment.

Let again the function $f$ describe the general relationship between variables $X$ and $Y$.

As sketched out in @fig-GeneralCorrection we want to first find the orthogonal (extant) width in a point $(x_0, f(x_o))$ on the graph, which corresponds to the perceived width, and then correct the vertical width accordingly to match with the audience's expectation.

The orthogonal width (see sketch in @fig-GeneralCorrection) is given as the line segment between endpoints $(x_1, f_1(x_1))$ and $(x_2, f_2(x_2))$, where $f_1$ and $f_2$ denote the vertical shifts of function $f$ by $-\ell/2$ and $\ell/2$, respectively, where $\ell$ is defined as the overall line length, $\ell > 0, \ell \in \xR$.
These endpoints are determined as the intersection of the line orthogonal to the tangent line in $(x, f(x))$ and graphs $f_1$ and $f_2$.

The orthogonal line through $(x_o, f(x_o))$ is given in point-vector form as $$
{x_o \choose f(x_o)} + \lambda {f^\prime(x_o) \choose 1}, 
$$

for any real-valued $\lambda$.
The extant (half-)widths are then given as ${|\lambda| \sqrt{1 + f^\prime(x_o)^2}}$.
This expression describes the quantity that we perceive rather than the quantity that we want to display ($\ell/2$), which leads us to a general correction factor of \$ {\ell/2 \cdot \left(\|\lambda\| \sqrt{1 + f^\prime(x_o)^2}\right)\^{-1}} \$.
Note that this yields in general two solutions: one for positive, one for negative values of $\lambda$ corresponding to upper and lower (half-)extant width.

In order to get actual numeric values for $\lambda$, we need to find end points of the extant line width as solutions of intersecting the orthogonal line and the graphs of $f_1$ and $f_2$.
We find these end points as solutions in $x$ and $\lambda$ of the system of equations:

$$ x - x_o = \lambda f^\prime(x_o) $$ {#eq-general-1} 
$$ f(x) - f(x_o) = -\lambda \pm \ell/2 $$ {#eq-general-2}

Note that the above system of equations involves function values $f(x)$, which implies that solving this system requires numerical optimization for any but the most simple functions $f$.

In the following two sections we make use of Taylor approximations of first and second order to find approximate solutions to end points as sketched out in @fig-linear-quadratic.

::: {#fig-linear-quadratic layout-ncol="3"}
![General Correction](figure/fig-generalcorrectioncartoon-1.png){#fig-GeneralCorrection fig-alt="General correction for the sine illusion"}

![Linear Approximation](figure/fig-generalcorrectioncartoon-2.png){#fig-linear-approx fig-alt="Linear approximation to correct the sine illusion"}

![Quadratic Approximation](figure/fig-generalcorrectioncartoon-3.png){#fig-quad-approx fig-alt="Quadratic approximation to correct the sine illusion"}

Methods based on Approximations to f(x).
(a) is the general correction approach, and may require numerical optimization to obtain exact solutions for $(x_1, y_1)$ and $(x_2, y_2)$.
(b) uses a first-order Taylor series approximation to $f(x)$ and (c) uses a second-order Taylor series approximation to $f(x)$.
The intersection of the function $f(x) \pm \ell/2$ and the orthogonal line, $(x_1, y_1), (x_2, y_2)$ must be obtained to determine the necessary correction factor.
:::

For the linear approximation to $f(x)$ we make use of $f(x) \approx f(x_0) + (x - x_0) f^\prime(x_0)$, which together with @eq-general-1 and @eq-general-2 yields a correction factor in $x_0$ of $$ \ell_{\text{new}}(x_0) = \ell_{\text{old}} \sqrt{1 +  f^\prime(x_0)^2}.$$

Note that the linear method gives the same result as a varying slope extension from a trigonometric approach suggested by @schonlau:2003 (pg. 3) and used in @marie:2013.

A second-order Taylor polynomial approximation to $f(x)$ additionally accounts for the asymmetry in the extant widths on either side of the center trend line.

A quadratic approximation to $f(x)$ is achieved using the approximation $f(x) \approx f(x_0) + f^\prime(x_0)(x-x_0) + 1/2 f^{\prime\prime}(x_0)(x-x_0)^2$.
This simplifies the system of @eq-general-1 and @eq-general-2 to the following quadratic equation in $\lambda$: $$
f^{\prime\prime}(x_0)  f^\prime(x_0)^2 \lambda^2  + 2(f^\prime(x_0)^2 + 1) \lambda  \pm \ell = 0,
$$ which leads us to corrections for the half lengths as (see $$
\ell_{\text{new}_1}(x_0) = 1 /2 \cdot  \left(v + \sqrt{ v^2 +  f^{\prime\prime}(x_0) f^\prime(x_0)^2\cdot  \ell_{\text{old}}}\right) \cdot v^{-1/2}
$$ {#eq-q1}

$$
\ell_{\text{new}_2}(x_0) = 1 /2 \cdot  \left(v + \sqrt{ v^2 -  f^{\prime\prime}(x_0) f^\prime(x_0)^2\cdot  \ell_{\text{old}}}\right) \cdot v^{-1/2} 
$$ {#eq-q2}

where $v = 1 + f^\prime(x_0)^2$.

::: {#fig-GeneralQuadraticCorrection layout-ncol="3"}
![Uncorrected](figure/fig-UncorRresults-1.png){#fig-quad-uncor fig-alt="Uncorrected sine illustion, from 0 to 2$\\pi$ on the x-axis, following $y=2\\sin(x)$."}

![Linear correction](figure/fig-UncorRresults-1.png){#fig-quad-linear fig-alt="Sine illustion, from 0 to 2$\\pi$ on the x-axis, following $y=2\\sin(x)$, corrected using the linear approximation."}

![Quadratic correction](figure/fig-UncorRresults-1.png){#fig-quad-quad fig-alt="Sine illustion, from 0 to 2$\\pi$ on the x-axis, following $y=2\\sin(x)$, corrected using the quadratic approximation."}

Quadratic Approximation.
In the quadratic approximation top and bottom segments of the vertical lines are adjusted separately.
:::

Adjusting the top and bottom segments of the vertical lines separately so that the extant width is constant breaks the illusion, but slightly distorts the sinusoidal shape of the peaks.

@fig-GeneralQuadraticCorrection shows the correction factor based on a quadratic approximation compared to the untransformed data.
Unlike the linear solution, the half-segments here are not necessarily of the same length, and thus there are separate correction factors for each half-segment.

The quadratic correction breaks whenever the expression in the square root of @eq-q1 and @eq-q2 becomes negative, i.e.\~whenever $v^2 \pm \ell\cdot f^{\prime\prime}(x)\cdot f^\prime(x)^2 < 0$.
This happens for combinations of large values of $\ell$, which signify a large vertical extent, or large conditional variability $E[Y|X]$, and simultaneous large changes in the slope of the main trend, i.e.\~large values of the curvature $f^{\prime\prime}(x)$.
In the linear approximation of $f$ the same situation leads to a massive overcorrection of the vertical lines, changing the shape of the 'corrected' function beyond recognition.

Similar to the correction of the $x$-axis, we can use a weighted approach to find a balance between counteracting the illusion and representing the original data:

$$
\ell_{new_w}(x) = (1-w) \cdot \ell_{old} + w \cdot \ell_{new}(x).
$$ {#eq-ytrans-weighted}

# Transformations in Practice -- a User Study {#sec-study}

::: aside

Annotation Key

- [Study design and data collection]{.design}

- [Setting - location, timeframe, recruitment/inclusion criteria]{.setting}

- [Sampling method]{.sampling}

- [Variables collected (and any derived variables)]{.variables}

- [Statistical analysis methods]{.statistics}

:::


In order to more fully understand the sine illusion and test the proposed corrections, [we created an applet to allow users to investigate the illusion's prominence with respect to its parameters.
Users can examine the sine illusion by changing line length, the function's amplitude, and compare corrections in $x$-axis and $y$-values to uncorrected data.
All corrections proposed in this paper are implemented in a Shiny applet [@shiny] located at http://bit.ly/1ldgujL]{.design}.

[We employed a second Shiny applet (http://bit.ly/SzDnTc) to collect data on users' preferences on the amount of correction used, i.e. we are interested in identifying a range of 'optimal weights' in each of the corrections.
This applet presents users with a graph that is the result of a correction in $x$ or $y$ with a randomly selected starting weight value .
Users are asked to adjust the graph until the lines appear to be the same size, that is, until the illusion is no longer present (from lower weight values) or is appropriately corrected (from higher weight values).
Users manipulate the graph using a plus/minus button to adjust the amount of correction used.
Underlying this adjustment is the value of the weight $w$ as defined in @eq-xtrans-weighted and @eq-ytrans-weighted.
The numerical value of $w$ was hidden from the user to prevent anchoring to a specific numerical value.
The applet utilizes the linear $Y$ transformation and does not break under any combination of parameters tested in this experiment.]{.design}

A low initial weight ($w_0$ close to 0) indicates that the amount of correction is low and the response from a trial like this will give us an idea of the minimal amount of weight necessary to break the illusion, while a high initial weight ($w_0$ close to 1) indicates that the data are fully corrected.
Generally, responses from the two different types of trials do not result in the same threshold weight, but rather indicate a range of acceptable weights.

It is of additional interest to determine whether and how much these optimal weights are subject-specific or population-based, whether they depend on the initial weight, and how much within-subject variability we find compared to between-subject variability.

## Study Design

The study aims to determine the range of "optimal" transformation weights for each transformation type.
Psychophysics methodology typically approaches threshold estimation by using the method of adjustment [@goldstein], where stimuli are provided showing states both above and below the hypothesized optimal value and participants adjust the stimuli until the stated goal is met (in this case, until the lines appear to have equal length).
It is expected that there will be a difference in user-reported values from below and from above, and these values are typically averaged to produce a single threshold value (the results from this model are provided in @sec-psychophysics).
Instead of averaging these values, we use a mixed model to compare user responses for different starting points to be able to estimate the *range* of transformation weights.

[The study is set up as a fractional factorial design of correction type ($x$ or $y$) and starting weight $w_0$.
Each participant is asked to evaluate a total of twelve situations, six of each correction type.
Starting weights were chosen as follows: each user was given a trial of each type starting at 0 and 1.
The remaining four trials of each type had starting weights chosen with equal probability from $0.25$ to $0.75$ (see @fig-weightdist).]{.sampling}

[We decided to have a higher coverage density for starting weights around 0.6 after a pilot study indicated a preference for that value.
Using a distribution with a wide coverage allows us to more fully explore the space of plausible weights $w$ while focusing on the $(0,1)$ interval and enabling precise estimation of the optimal weight in the region indicated by the pilot study.]{.design}

![Overview of possible starting weights. Weight values are discrete, but staggered so as to provide fine-grained adjustments around 0.6 and more coarse discriminatory information toward the outside.](figure/fig-study-weight-dist-1.png){#fig-weightdist fig-alt="Overview of possible starting weights. Weight values are discrete, but staggered so as to provide fine-grained adjustments around 0.6 and more coarse discriminatory information toward the outside."}

[A trial begins with the presentation of a graph at the chosen starting weight $w_0$.
Participants are asked to adjust the graph using increment and decrement buttons.
A trial ends with the participant clicking the 'submit' button, at which point the weight for the final adjustment is recorded.]{.design}
[This provides a clear starting value and ending value, allowing us to assess the range of optimal values for each participant.
In addition to starting weight, correction type, and anonymized user-specific data (partial IP address, hashed IP address, and hashed browser characteristics), each incremental weight is recorded with a corresponding time stamp.
Specifications of a user's browser turned out to be sufficient as an anonymous, yet individual 'fingerprint'.]{.variables}

## Results

[Participants were recruited from Amazon Mechanical Turk and the [reddit](http://reddit.com/r/SampleSize) community.]{.setting}
[As this study was conducted outside a laboratory setting, we can not gauge a participant's willingness to follow the guidelines and put in their best effort.
This, besides potential technical issues (server outage, speed of response) make a careful selection of data going into the analysis necessary.
The specific data exclusion criteria are provided in @sec-exclusion.]{.setting}

[The following analysis is based on the cleaned data, consisting of 125 participants with 1210 valid trial results.
The results from the standard psychophysics model (provided in @sec-psychophysics) suggest that some transformation is necessary to break the illusion, yet a complete transformation is not needed.
For an estimate of the range of acceptable transformation weights we use a linear model that incorporates starting points other than 0 and 1, and allows for user-specific variability.]{.statistics}

[In order to account for user-level variability, we fit a random effects model for the adjusted weight value as a function of starting weight and trial type, with a random intercept for each participant.
The exact model specification and parameter estimates can be found in @sec-model.]{.statistics}

![Simulation results from the fitted model, facetted by correction type. Fixed effects results are shown as histograms; the red values display the results when starting from an uncorrected plot and are concentrated around $w=0.1$ for $X$ and $w=0.14$ for $Y$; the blue values represent user-chosen weights when starting from a fully corrected plot and are concentrated around $w=0.62$ for $X$ and $w=0.67$ for $Y$. Additionally, 95% bootstrap intervals are shown as horizontal line segments above the histograms; these intervals are for the lower and upper bounds of the "preferred weight interval" tested in the experiment. User-level density curves show the individual variability around fixed effects $\alpha_*$ and $\alpha_*+\beta$.](figure/fig-results-analysis1-1.png){#fig-MixedModelResults fig-alt="Simulation results from the fitted model, facetted by correction type. Fixed effects results are shown as histograms; the red values display the results when starting from an uncorrected plot and are concentrated around $w=0.1$ for $X$ and $w=0.14$ for $Y$; the blue values represent user-chosen weights when starting from a fully corrected plot and are concentrated around $w=0.62$ for $X$ and $w=0.67$ for $Y$. Additionally, 95% bootstrap intervals are shown as horizontal line segments above the histograms; these intervals are for the lower and upper bounds of the preferred weight interval tested in the experiment. User-level density curves show the individual variability around  fixed effects $\\alpha_*$ and $\\alpha_*+\\beta$."}

@fig-MixedModelResults gives an overview of the relationship between starting weights and user-preferred weight values.
Higher starting weights are associated with higher user-submitted values, while lower starting weights result in lower user-submitted values.
The ranges of optimal weights are similar under both transformations.
Boundaries for the $X$ transformation are slightly lower than boundaries for $Y$.

[Bootstrap simulations for each of the coefficients suggest that the range of acceptable shrinkage values $w$ is between 0.098 and 0.625 for $x$ and 0.144 and 0.671 for $y$, where the lower value is the estimate starting at $w=0$ and moving up, and the upper value is the estimate starting at $w=1$ and moving down.]{.statistics}
This suggests that either correction is preferable to an uncorrected graph, and that a weighted correction is preferable to the fully corrected graph, as neither 0 nor 1 is contained in any overall interval.
In addition to showing the strength of the correction, this experiment also demonstrates the strength of the illusion itself: corrected line lengths appear more uniform than uncorrected ones, even though the corrected lengths are not uniform while the uncorrected lengths are completely uniform.

# Application: US Gas Prices {#sec-example}

@fig-gasprices shows daily gas prices for a time frame between 1995 to 2014 as published in the Energy Information Administration's historical database of gas prices [@EIA].
This data set includes prices for all three grades of gasoline as well as two chemical formulations which are sold in different geographic areas across the United States [@EIA-reformulated].

![US Gas prices from 1995 to 2014 steadily increase over the time frame, with some dramatic short-term changes.](figure/fig-gasprices-pictures-1.png){#fig-gasprices fig-alt="US Gas prices from 1995 to 2014 steadily increase over the time frame, with some dramatic short-term changes."}

![Standard deviation of daily gas prices between 1995 and 2014. The doubling of the standard deviation over the time frame is masked in @fig-gasprices](figure/fig-gaspricevariance-1.png){#fig-gasvariance fig-alt="Standard deviation of daily gas prices between 1995 and 2014. The doubling of the standard deviation over the time frame is masked in @fig-gasprices"}

There is a clear increase in daily gas prices over time as well as several dramatic price changes, which mask the steady increase in variance shown in @fig-gasvariance.
Instead, we perceive an increase in variability in the frequent ups and downs along the overall trend.
In particular, the strong decrease in gas prices at the end of 2008 seems to be associated with a low variance.
This is an effect of the sine illusion, and the actual variability in Oct 2008 is higher than in previous months.
In order to judge variability better along the trend line we apply the two different corrections to this data, using a trend line fit based on smoothing splines to obtain the necessary first and second derivatives.

![Corrected gas price data using X-transformations with $w=1$ and $w=0.36$](figure/gas-x-corrected.png){#fig-gasprices-x-correct fig-alt="Corrected gas price data using X-transformations with $w=1$ and $w=0.36$"}

@fig-gasprices-x-correct shows the results from the $X$ transformation applied to the gas prices.
The figure on top is a fully corrected version, while the one below only uses $w=0.36$, the midpoint of the range of experimentally determined acceptable values, for the transformation.
At $w=1$, the transformation is severe, but it becomes clear that the variance between 1995 and 2000 is lower than it is between 2009 and 2014.
When $w=0.36$, the transformation is much less noticeable but yields a near-constant absolute slope of the fitted line.

The minor effect of the weighted transformation on individual x-values contrasts with the effectiveness of the transformation in reducing the illusion; this is best seen in the fitted line, which is distinctly (piecewise) curved in the uncorrected data and appears to be much more piecewise linear in the corrected data, even at the reduced weighted value.

Similar to the $X$ transformation, the $Y$ transformation highlights local fluctuation in the variability of daily gas prices much more than the untransformed data (the trend line is not adjusted, but the individual data points are not accurate and are negative in the $w=1$ transformation).
@fig-gasprices-y-correct shows $Y$ transformations for the data.
Again, we show a full transformation (top) and a transformation based on the midpoint of the previously determined acceptable region of $w=0.40$.
in the full transformation it is clear that the variance is nearly constant between 1995 and 2000 and then begins to increase with the price of gas.
When $w=0.40$, the transformation is much less noticeable, and the resulting $y$-axis scale is much more similar to the uncorrected data.

![Corrected gas price data using Y-transformations with $w=1$ and $w=0.40$](figure/gas-y-corrected.png){#fig-gasprices-y-correct fig-alt="Corrected gas price data using Y-transformations with $w=1$ and $w=0.40$"}

# Conclusions

The sine illusion is a frequent occurrence in statistical graphics, and displays should therefore be thoughtfully considered to minimize its effect visually and acknowledge its influence.

The illusion is persistent and powerful in the sense that it is very difficult to resolve without modifying the visual stimulus directly.
While systematically modifying the data is uncommon in statistics, this approach is not out of place in the visual arts or architecture.
As far back as 400 BC the builders of the Parthenon ensured a straight appearance of the columns from afar by widening columns at the center, thereby counteracting the effects of the Hering illusion [@naturalscenes; @hering].
Similarly, painters often exaggerate color hues used in shadows to account for color constancy in the brain.
The systematic modifications we suggest here are also comparable to chloropleth maps, which scale a region's area based on population.

We cannot counteract the illusion and represent the data visually without an intervention that is drastic enough to remove the three-dimensional context the sine-illusion induces.
The proposals in this paper for transformations in $x$ and $y$ provide the means to temporarily correct the data as a diagnostic measure, perhaps using an applet or R package for that purpose.
These corrections are significant not only because of their implications for statistical graphics, but because previous attempts to resolve optical illusions using geometry have not met with success [@westheimer2008illusions].
These corrections are only a first step and could be improved upon; currently, the corrections break down for extreme (secant) values, but multiple iterations of the correction procedure %will likely resolve some of these issues (though remove the convenience of a functional form for the transformation).
Similarly, the $y$ corrections proposed here extend the line lengths (or for actual data, increase the deviation from the smooth line) -- some normalization might make the corrections less noticeable.

Our primary goal is to raise awareness of the illusion and its implications for statistics; the use of plots to guide the modeling process can leave us vulnerable to overlooking changes in the variance due to the illusion.
While best practice has been to plot the residuals separately, this removes the context of the data and is not practical before there is a model.
The proposed transformations require only a nonparametric smooth, maintain the context of the data, and are readily interpretable.

The data for this study were collected with approval from IRB-ID 13-257.

# References 

::: {#refs}
:::

# Examples of the Sine Illusion in graphics {#sec-app-graphics .appendix}

@fig-playfair-debt shows the famous chart by William Playfair showing trade between England and the East Indies.

![Playfair's graph of exports to and imports from the East Indies demonstrates that the line width illusion is not only found on sinusoidal curves but is present whenever the slope of the lines change dramatically. The increase in both imports and exports circa 1763 does not appear to portray as large of a deficit as that in 1710, even though they are of similar magnitude.](images/PlayfairExportImports.png){#fig-playfair-debt fig-alt="Playfair's graph of exports to and imports from the East Indies demonstrates that the line width illusion is not only found on sinusoidal curves but is present whenever the slope of the lines change dramatically. The increase in both imports and exports circa 1763 does not appear to portray as large of a deficit as that in 1710, even though they are of similar magnitude."}

The shaded area on the chart is named "balance against England", suggesting that the difference between the lines is of main importance.
This difference in trade is encoded as the difference between the lines along the vertical axis.
However, the vertical distance between two lines provides a much less visually salient cue than the orthogonal width between the lines.
This results in an underestimation [@cleveland:1984] of the difference in trades around 1763, which is of a much higher (about 1.5 fold) magnitude as around 1770, but appears much smaller.

# Transformation of the horizontal axis {#sec-app-xtrans .appendix}

As the slope is determined by the aspect ratio, we are free to choose it and w.l.o.g. we get for each piece $T_i$: $$f(T_i(x)) = \pm a x + b_i. $$ This means that $T_i$ is essentially an inverse of function $f$, with each piece defined by the intervals on which the inverse of $f$ exists: let $\left\{x_0 = \min(x), x_1, ..., x_{K-1}, x_K = \max(x) \right\}$ be the set of values with local extrema enhanced by the boundaries of the $x$-range, i.e. $f^\prime(x_i) = 0$ for $i = 1, ... , K-1$ and $f^\prime(x) \neq 0$ for any other values of $x$.
Then each interval of the form $(x_{i-1}, x_i)$ defines one piece $T_i$ of the transformation function $T(x)$.
We will define $T_i$ now as a combination of a linear scaling function and the inverse of $f$, which we know exists for interval $(x_{i-1}, x_i)$.

Let function $s = \s{[a,b]}{[c,d]}$ be the linear scaling function that maps the interval $(a,b)$ linearly to the interval $(c,d)$.
This function is formally defined as

$$s(x) = \s{[a,b]}{[c,d]} (x) = (x-a)/(b-a) \cdot (d-c) + c \text{ for all } x \in (a,b).$$

Note that the slope of function $s$ is given as $s^\prime(x) = (d-c)/(b-a).$

Two scaling functions can be evaluated one after the other, only if the image (i.e. $y$-range) of the first coincides with the domain (i.e. $x$-range) of the second.
This consecutive execution results in another linear scaling: $$\s{[e,f]}{[c,d]}  \left(  \s{[a,b]}{[e,f]}(x) \right) = \s{[a,b]}{[c,d]} (x).
$$

In our situation let the scaling function $s$ be given as: $$
s{[c,d]}{f([x_{i-1}, x_i])}(x) = f(x_{i-1}) + (x-c)/(d-c) \cdot (f(x_{i}) - f(x_{i-1}))),
$$ where $f([x_{i-1}, x_i])$ is defined as the interval given by $(\min(f(x_{i-1}), f(x_i)), \max(f(x_{i-1}), f(x_i)))$.
Note that $s$ has either a positive or negative slope depending on whether $f(x_{i-1})$ is smaller or larger than $f(x_i)$, respectively.

Then the transformation in the $x$-axis, $T(x)$ is defined piecewise as a combination of $T_i$, where each $T_i$ is given as:
$$
T_i(x) = f^{-1}\left( \s{[c_i,d_i]}{f([x_{i-1}, x_i])}(x) \right). 
$$ {#eq-x-transformation}

Using this definition for the transformation makes $f(T(x))$ a piece-wise linear function with parameters $c_i$ and $d_i$, i.e. for $x \in (c_i,d_i)$ we have \[ f(T(x)) = f (f\^{-1}(\s{[c_i,d_i]}{f([x_{i-1}, x_i])}(x))) = \s{[c_i,d_i]}{f([x_{i-1}, x_i])}(x).
\] Correspondingly, the slope of $f(T_i(x))$ is $(f(x_{i}) - f(x_{i-1})))/(d_i-c_i)$.
In order to make the slope the same on all pieces $T_i$ of $T$, we need to define $c_i$ and $d_i$ with respect to the function values on the interval $(x_{i-1}, x_i)$.
There are various options, depending on how closely the $x$-range of $T$ should reflect the original range: for $[c_i, d_i] = \range {f([x_{i-1}, x_i])}$ the new $x$-range is the range of $f$ on $(x_{i-1}, x_i)$, but with the advantage that the scaling function simplifies to the identity or a simple shift.

In order to preserve the original $x$-range, we need to invest into a bit more work for the scaling.
With an identity scaling, each $T_i$ maps from the range of $f$ on $(x_{i-1}, x_i)$ to the same range.
Overall we can therefore set up the function $T$ to map from the interval given by the sum of the function's 'ups' and 'downs', i.e. $(0, \sum_{i=0}^K |f(x_i) - f(x_{i-1})|)$, to the range of $f$ on $(x_0, x_K)$.
This ensures that all pieces $f(T_i)$ have the same slope (of $|1|$).We can then use another - global - linear scaling function to map from the range of $x$, i.e. interval $(x_0, x_K)$ to $(0, \sum_{i=0}^K |f(x_i) - f(x_{i-1})|)$, yielding a transformation function $T$ of

$$ T (x) = (f\^{-1} \circ \s{[c_i,d_i]}{f([x_{i-1}, x_i])} \circ \s{(x_0, x_K)}{(0, \sum_{i=0}^K |f(x_i) - f(x_{i-1})|)}) (x),$$
where $c_i$ and $d_i$ are given as $$ c_i = \sum*{j=0}\^{i-1} \|f(x_j) - f(x*{j-1})\| \text{ and } d_i = \sum*{j=0}\^{i} \|f(x_j) - f(x*{j-1})\|.
$$
We can write the difference $|f(x_j) - f(x_{j-1})|$ as $\int_{x_{j-1}}^{x_j} |f^\prime(z)|dz$.
This shows equation @eq-xtrans.

# Reformulation of the quadratic approximation {#sec-app-quadratic .appendix}

A quadratic equation in $\lambda$ of the form 
$$
a\lambda^2 + b\lambda + c = 0,
$$ {#eq-quadratic.equation} 
where $a, b,$ and $c$ are real-valued parameters the solutions take on the form $$\lambda_{\pm} = \frac{-b \pm \sqrt{b^2 - 4ac}}{2a} \stackrel{*}{=} 2c\left(-b \pm \sqrt{b^2 - 4ac}\right)^{-1}.$$

$^*$ if $b \neq \pm \sqrt{b^2 - 4ac}$, i.e.
$a, c \neq 0$.

Application to quadratic approximation to $f$: in the example, we have the following equivalencies: 
$$
\begin{align}
a &= f^{\prime\prime}(x_0) f^\prime(x_0)^2 \\
b &= 2(1 + f^\prime(x_0)^2) \hspace{.5in} > 0 \text{ for all } x \\
c &= \pm \ell 
\end{align}$$
For a valid solution for the correction factor, we have to assume that $\lambda$ is a factor that extends the original extant width (in absolute value).

$$
\lambda_{1/2} = \ell \left(v + \sqrt{ v^2 \pm  f^{\prime\prime}(x_0) f^\prime(x_0)^2\cdot \ell}\right)^{-1} 
$$
for $v = 1 + f^\prime(x_0)$.
This gives the results as shown in @eq-q1 and @eq-q2.

# Random Effects Model and Detailed Results {#sec-model .appendix}

## Data Cleaning {#sec-exclusion .appendix}

The following exclusion criteria were used to clean the raw data obtained from Amazon Mechanical Turk:

-   Participants did not interact with the applet: we required participants to use the adjustment at least once in order to include data for this trial (592 trials removed).
-   Participants finished fewer than four trials: while participants were asked to complete twelve trials, some did not finish all of those. In order to stabilize predictions of random effects, participants' data were excluded if there were fewer than four trials (78 out of a total of 203 participants).
-   Out-of-bounds results: weights leading to severely over- or under-corrected results were excluded from the analysis. For trials to adjust $Y$-values, weights outside of $[-2.5, 3.5]$ show dramatically unequal line lengths; weights from $X$-transformations outside the range of $[-2,2]$ do not preserve the underlying function shape and concavity. @fig-overtransform shows results at the threshold of acceptability. Only more severely distorted results were excluded from the analysis (12 of the $X$ and 5 of the $Y$ trials out of 1227 trials remaining after application of other criteria).

![Overcorrected transformations excluded from the analysis. Transformation weights outside of the intervals \[-2.5, 3.5\] for $y$ and \[-2,2\] for $x$ produce figures which do not maintain the underlying function shape (in $x$) or which are composed of extremely uneven length lines (in $y$). Trials with final results that were more extreme than these examples were excluded from the analysis.](figure/fig-overcorrectlimits-1.png){#fig-overtransform fig-alt="A 2x2 array of charts showing low and high cutoffs for Y and X transformations."}

## Psychophysics Model Results {#sec-psychophysics .appendix}

The psychophysics model shown in @fig-psycho is based on weighted averages (by adjustment type) of all trials with starting weights $w_0 = 0$ and 1.

![Estimated density of participant-level means using the standard psychophysics method of limits analysis described in @goldstein. The overall means are both near 0.4, however, there is quite a bit of user-level variability.](figure/fig-meanDists-1.png){#fig-psycho fig-alt="Estimated density of participant-level means using the standard psychophysics method of limits analysis described in @goldstein. The overall means are both near 0.4, however, there is quite a bit of user-level variability."}

Transformation | Threshold | Parameter | Estimate | 95% C.I.
--- | --- | --- | --- | ---
X | Lower | X | 0.097 | (0.045, 0.150) 
  | Upper | X +  | 0.625 | (0.570, 0.682) 
Y | Lower | Y | 0.143 | (0.097, 0.188) 
  | Upper | Y +  | 0.671 | (0.626, 0.718)

: Fixed effect estimates of @eq-model1 for the boundaries for reasonable weights.
In parentheses, 95% parametric bootstrap confidence intervals are given based on  @eq-model1 (N =1000).
{#tbl-psychotable}

According to this analysis, the optimum transformation value for $x$ is 0.35, and the optimum transformation value for $y$ is 0.45.
@fig-psycho shows the estimates and 95% Wald intervals for the mean, as well as estimated density of participant-level responses.

## Random Effects Model Formulation {.appendix}

Let $W_{ij}$ denote the final adjustment to weight by participant $i$, \$ 1 \le i \le 125\$ , on trial $j$, $1 \le j \le n_i$.
We model the final weight $W_{ij}$ as a function of the correction type $T(i,j)$ (where $T(i,j) \in  \{X, Y\}$), and starting weight $X_{ij}$, with a random intercept for participant to account for subject-specific ability: $$
\begin{align}
W_{ij} &= \alpha_{T(i,j)} + \beta X_{ij} + \gamma_{i, T(i,j)} + \epsilon_{ij}\\
& \gamma_{iX} \stackrel{\text{ i.i.d.}}{\sim} N(0, \eta_X^2) , \ \gamma_{iY} \stackrel{\text{ i.i.d.}}{\sim} N(0, \eta_Y^2) ,\notag  \\
& \epsilon_{ij} \stackrel{\text{ i.i.d.}}{\sim} N(0, \sigma^2)  \text{ and } \text{Cov}(\gamma, \epsilon) = 0\notag 
\end{align}
$$ {#eq-model1}

$\alpha_{T(i,j)}$ is either $\alpha_X$ or $\alpha_Y$, describing the lower threshold of the acceptable range for each of the types of correction, while $\alpha_X+\beta$ and $\alpha_Y + \beta$ describe the upper thresholds for the respective correction.

We can therefore interpret $\beta$ as the length of the interval of plausible weights.
Additionally, this allows the interpretation of the quantity $(\alpha_* + \beta/2)$ as equivalent to the estimate of the optimal weight based on the psychophysics methodology.

The fitted model parameters are shown in @tbl-fixedeffectsresults and @tbl-randomeffectsresults.

| Transformation | Threshold | Parameter          | Estimate | 95% C.I.       |
|----------------|-----------|--------------------|----------|----------------|
| X              | Lower     | $\alpha_X$         | 0.097    | (0.045, 0.150) |
|                | Upper     | $\alpha_X + \beta$ | 0.625    | (0.570, 0.682) |
| Y              | Lower     | $\alpha_Y$         | 0.143    | (0.097, 0.188) |
|                | Upper     | $\alpha_Y + \beta$ | 0.671    | (0.626, 0.718) |

: Fixed effect estimates of @eq-model1 for the boundaries for reasonable weights. In parentheses, 95% parametric bootstrap confidence intervals are given based on eq-model1 ($N$=1000). {#tbl-fixedeffectsresults}

| Groups      | Correction | Parameter | Estimate | 95% C.I.       |
|-------------|------------|-----------|----------|----------------|
| Participant | X          | $\eta_X$  | 0.171    | (0.167, 0.247) |
| Participant | Y          | $\eta_Y$  | 0.145    | (0.107, 0.179) |
| Residual    |            | $\sigma$  | 0.304    | (0.290, 0.317) |

: Overview of random effects for model @eq-model1, including 95% confidence intervals based on parametric bootstrap results ($N$=1000). {#tbl-randomeffectsresults}

@tbl-randomeffectsresults gives an overview of the variance estimates.
95% confidence intervals are, based on 1000-fold parametric bootstrap of model @eq-model1.
All variance components are significant and relevant; variability within a single individual's trials is about half the size of variability across participants.

We use parametric bootstrap to generate responses for each correction type and each participant from the model, which we use to both create user-level densities, population-level densities, and bootstrap intervals for model parameters.

The variability of the random effects for each trial type is similar; but the model benefits significantly from allowing separate random effects for individual's variability by correction type (0.1452 and 0.1705 for $Y$ and $X$ transformations, respectively, as opposed to 0.3044 for the overall variability).
The interaction between starting weight and trial type was not significant, however, and was thus removed from the model ($p$-value = 0.9010).
